<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" lang="en">

<head>
    <title>O HOMEM BICENTENÁRIO</title>
    <link type="text/css" rel="stylesheet" href="css/book.css" />
</head>

<body>
    <h1>4<br />☆<br />Para que Vos Ocupeis Dele</h1>

    <p class="fl"><i>As Três Leis da Robótica:</i></p>
    <ol class="thin nospace italic justify">
        <li>Um robô não deve fazer mal a um ser humano ou, por inação, permitir que um ser humano sofra qualquer mal.</li>
        <li>Um robô deve obedecer a qualquer ordem dada por um ser humano, desde que essa ordem não interfira com a execucão da Primeira Lei.</li>
        <li>Um robô deve proteger a sua existência, desde que esta proteção não interfira com a Primeira e Segunda Leis.</li>
    </ol>

    <h4>1.</h4>

    <p>Keith Harriman, que agora já contava com doze anos como Diretor de Pesquisas da United States Robots and Mechanical Men, Inc., achava que absolutamente não podia ter certeza se estava agindo certo. A ponta de sua língua passava sobre seus lábios, grossos mas um tanto descorados. E, para ele, parecia que a imagem holográfica da grande Susan Calvin, que estava acima dele, estática, sem sorrir, nunca lhe parecera antes tão sombria.</p>
    <p>Pouco à vontade, ele apagou aquela imagem da maior roboticista da história porque ela o enervava. (Ele tentava encarar a imagem como sendo algo destituído de vida, mas nunca tivera sucesso nisso.) Desta vez ele nem sequer ousou e o olhar fixo dela, de há muito morto, perturbava-o, ainda que lateralmente.</p>
    <p>Ele teria de dar um passo incômodo e humilhante.</p>
    <p>Em frente dele estava George Ten, calmo, não afetado quer pela visível inquietação de Harriman, quer pela imagem da santa padroeira da robótica, a fulgurar err seu nicho, mais acima.</p>
    <p>Harriman disse: — Na verdade, George, não tivemos até agora oportunidade de falar abertamente sobre isto. Faz tanto tempo que você não tem estado conosco e não tive uma boa oportunidade de estar a sós com você. Agora, porém, gostaria de discutir o assunto com alguns detalhes.</p>
    <p>— Bem que eu quero fazer isso — falou George. — Em minha permanência na U.S. Robots, cheguei a perceber que a crise tem alguma coisa a ver com as Três Leis.</p>
    <p>— Sim. Naturalmente, você conhece as Três Leis.</p>
    <p>— Conheço.</p>
    <p>— Sim, sei que você conhece. Mas vamos escavar mais fundo e considerar o problema verdadeiramente básico. Em dois séculos de, permita-me dizê-lo, considerável sucesso, a U.S. Robots nunca tentou persuadir os seres humanos a aceitarem os robôs. Só colocamos robôs onde se exige trabalho que seres humanos não podem fazer, ou em ambientes que os seres humanos considerarem inaceitavelmente perigosos. Os robôs têm trabalhado principalmente no espaço e isto limita o que temos sido capazes de fazer.</p>
    <p>— Isso — falou George — com toda segurança representa um amplo limite, dentro do qual a U. S. Robots pode prosperar.</p>
    <p>— Não, por duas razões. Em primeiro lugar, as fronteiras que nos são impostas inevitavelmente se contraem. No caso da colônia na Lua, por exemplo, conforme ela se torna mais sofisticada, diminui sua necessidade de robôs, e até esperamos que, dentro de alguns anos, os robôs sejam banidos da Lua. E isto se repetirá em cada mundo colonizado pela humanidade. Em segundo lugar, a verdadeira prosperidade é impossível sem robôs na Terra. Nós, aqui na U.S. Robots,, acreditamos firmemente que os seres humanos precisam de robôs e precisam aprender a viver com seus análogos mecânicos se se quiser manter o progresso.</p>
    <p>— E eles não aprendem? O senhor tem em sua mesa, Sr. Harriman, um terminal de computador que, assim entendo, está ligado com o Multivac da organização. Um computador é uma espécie de robô séssil, sem pés; um cérebro de robô não ligado a um corpo...</p>
    <p>— É verdade: mas isto também é limitado. Os computadores usados pela humanidade têm sido invariavelmente especializados para evitar humanizar demais uma inteligência. Um século atrás estávamos bem a caminho de uma inteligência artificial de tipo ilimitado através do uso de grandes computadores que denominávamos de Máquinas, Máquinas que limitavam sua ação de acordo com elas mesmas. Uma vez que elas resolveram os problemas ecológicos que ameaçavam a sociedade humana, elas próprias se defasaram. Continuarem a existir, assim raciocinaram, as colocaria no papel de muletas para a humanidade. E, uma vez que os robôs perceberam que isto magoaria os seres humanos, eles se condenaram a si mesmos, pela Primeira Lei.</p>
    <p>— E eles estavam certos, ao agirem assim?</p>
    <p>— Em minha opinião, não. Por sua ação, reforçaram o complexo de Frankenstein da humanidade; no íntimo, temem que qualquer homem artificial que criassem se voltaria contra seu criador. Os homens temem que os robôs possam substituir os seres humanos.</p>
    <p>— E você próprio não receia isto?</p>
    <p>— Sei mais do que isso: enquanto existirem as Três Leis da Robótica, não poderão. Poderão servir de <i>parceiros</i> da humanidade; podem tomar parte na grande luta para entenderem e sabiamente dirigirem as leis da natureza, de forma que, juntos, robôs e homens possam fazer mais do que os homens sozinhos. Mas sempre de uma maneira tal que os robôs sirvam aos seres humanos.</p>
    <p>— Mas, se no decorrer de dois séculos as Três Leis provaram que conseguem manter os robôs dentro dos limites, qual a fonte do descrédito dos seres humanos para com os robôs?</p>
    <p>— Bem — disse Harriman, coçando sua cabeça vigorosamente, de maneira tal que seus cabelos grisalhos se juntavam em tufos — mais por superstição, é claro. Infelizmente, há também alguns aspectos complexos em jogo, dos quais se aproveitam agitadores anti-robôs.</p>
    <p>— Com relação às Três Leis?</p>
    <p>— Sim, particularmente à Segunda Lei. Não há problema na Terceira Lei, como sabe: ela é universal. Os robôs sempre precisam se sacrificar pelos seres humanos, qualquer ser humano.</p>
    <p>— Logicamente — disse George Ten.</p>
    <p>— Talvez a Primeira Lei seja menos, satisfatória, visto que sempre é possível imaginar uma condição em que um robô precise desempenhar ou a Ação A ou a B, as duas sendo mutuamente restritas, sendo que qualquer uma das duas ações resultará em dano para seres humanos. Conseqüentemente, o robô precisa selecionar com rapidez qual das ações causará menor dano. Não é fácil exercitar os passos positrônicos do cérebro de um robô de maneira que ele possa fazer a possível seleção. Se a Ação A redundar em dano para um talentoso jovem artista e a B facilmente resultar num dano equivalente em cinco pessoas mais idosas sem mérito particular, qual ação será escolhida?</p>
    <p>— A Ação A — falou George. — Dano para um é menos dano que para cinco.</p>
    <p>— Sim, sempre os robôs foram planejados para decidirem dessa maneira. Sempre pareceu impraticável esperar que os robôs julgassem delicados aspectos como talento, inteligência, a utilidade geral de uma pessoa para a sociedade. Isto protelaria a decisão até um ponto tal em que o robô estaria efetivamente imobilizado. A isto chegamos por estatísticas. Felizmente, poucas são as crises em que os robôs precisam tomar decisões deste naipe... Isto, todavia, nos conduz à Segunda Lei.</p>
    <p>— A Lei da Obediência.</p>
    <p>— Sim: é constante a necessidade de obediência. Um robô pode existir durante vinte anos sem jamais ter de agir prontamente para impedir dano a um ser humano, ou se achar diante da necessidade de se arriscar a ser destruído. Contudo, durante todo este tempo, ele estará constantemente obedecendo a ordens... Ordens de quem?</p>
    <p>— De seres humanos.</p>
    <p>— De qualquer ser humano? Como pode você julgar um ser humano, a ponto de saber se deve obedecer-lhe ou não?!... Que é o homem, “para que Vos ocupeis dele”, George?</p>
    <p>Neste ponto, George hesitou.</p>
    <p>Apressadamente, Harriman retomou a palavra. — Uma citação bíblica. Isto não importa. Quero dizer: um robô deve seguir as ordens de uma criança? Ou de um idiota? Ou de um criminoso? Ou de uma pessoa perfeitamente decente, inteligente, mas que aconteça de ser inábil e, por conseguinte, que ignore as conseqüências indesejáveis de uma ordem sua? E se dois seres humanos derem ordens conflitantes a um robô, qual delas o robô deverá seguir?</p>
    <p>— Mas, em duzentos anos — falou George Ten — será que problemas deste tipo não se manifestaram e não foram resolvidos?</p>
    <p>Sacudindo energicamente a cabeça, Harriman respondeu: — Não! Temos sido embaraçados pelo próprio fato de nossos robôs terem sido utilizados unicamente em ambientes especializados, lá fora, no espaço, onde os homens que com eles lidam são peritos em seus campos profissionais. Não há crianças, não há idiotas, não há criminosos, nem ignorantes bem intencionados presentes. Mesmo assim, ocasiões houve em que ocorreu dano devido a ordens idiotas ou simplesmente impensadas. Tais danos, em ambientes especializados e limitados, puderam ser refreados. Na Terra, entretanto, os robôs <i>têm de ter</i> discernimento, porque senão os diabos, aqueles que estão contra os robôs, continuam sustentando que estão certos.</p>
    <p>— Então você precisa inserir no cérebro positrônico a capacidade de discernimento.</p>
    <p>— Exatamente. Começamos a reproduzir os modelos JG, nos quais os robôs podem avaliar cada ser humano em relação ao sexo, idade, posição social e profissional, inteligência, maturidade, responsabilidade social e assim por diante.</p>
    <p>— E como isto afetaria as Três Leis?</p>
    <p>— A Terceira Lei, de maneira nenhuma. Mesmo o mais valioso dos robôs precisa se autodestruir em prol do mais inútil ser humano. Não podemos alterar isso. A Primeira Lei só é afetada quando qualquer ação alternativa produzir dano. A qualidade, assim como a quantidade de seres humanos em questão, precisa ser levada em consideração, desde que haja tempo para tal avaliação e base para ela, o que não será muito freqüente. A Segunda Lei é que será a mais profundamente modificada, visto que cada obediência em potencial deve por em jogo um discernimento. A obediência do robô será mais lenta, exceto quando também estiver em questão a Primeira Lei, mas ele obedecerá mais racionalmente.</p>
    <p>— Mas os discernimentos requeridos são muito complicados.</p>
    <p>— <i>Muito</i>. A necessidade de proceder a tais discernimentos tornou tão lentas as reações de nossa primeira dupla de modelos, a ponto de se paralisarem. Nos modelos posteriores fizemos aperfeiçoamentos às custas da introdução de tantas novas trilhas no cérebro dos robôs que os" seus cérebros se tomaram volumosos demais. Contudo, em nosso último par de modelos acredito que temos o que queríamos. O robô não tem de fazer um julgamento instantâneo sobre o mérito de um ser humano e o valor de suas ordens. Ele começa obedecendo a todos os seres humanos, como qualquer robô £omum o faria, e, então é que ele <i>aprende</i>. Um robô cresce, aprende, e amadurece. É o equivalente de uma criança e precisa estar sob constante supervisão. Porém, à medida que cresce, ele pode mais e mais ficar sem supervisão, na sociedade terrestre. Finalmente, é um membro pleno dessa sociedade.</p>
    <p>— Seguramente isso responde às objeções dos que se opõem aos robôs.</p>
    <p>— Não — replicou Harriman, irritado. — Agora antepõem outras objeções. Não aceitarão o discernimento dos robôs. Dizem que um robô não tem o direito de marcar esta pessoa como sendo inferior àquela. Se um robô aceita ordens de A preferencialmente às de B, está ferreteando B, rotulando-o como menos importante do que A, e, neste caso, os direitos humanos de B foram violados.</p>
    <p>— E qual é a resposta para isso?</p>
    <p>— Nenhuma. Já desisti.</p>
    <p>— Estou vendo...</p>
    <p>— No que me toca... Transfiro-lhe o problema, George.</p>
    <p>— Para mim? — A voz de George Ten permaneceu no mesmo tom. Havia nela uma branda surpresa, mas que não o afetava ostensivamente. — Por que para mim?</p>
    <p>Tensamente, Harriman se manifestou: — Porque você não é um homem. Eu lhe disse que quero que os robôs sejam parceiros de seres humanos. Quero que você seja meu parceiro.</p>
    <p>Num gesto singularmente humano, George ergueu as mãos e exibiu-as, com as palmas voltadas para o outro: — E que é que eu posso fazer?</p>
    <p>— Pode-lhe parecer, de início, que você não pode fazer nada, George. Não faz muito tempo que você foi criado: ainda é uma criança. Você foi planejado de modo a não ficar repleto de informações originais. Por isso tive de lhe explicar a situação com tantos detalhes, de forma a deixar espaço para desenvolvimento. Mas sua mente evoluirá e você será capaz de abordar o problema sob um ponto de vista não humano. Onde eu não vislumbrar solução, pode ser que você, de seu enfoque, divise uma.</p>
    <p>— Meu cérebro foi desenhado por seres humanos. De que maneira ele pode ser não humano, indagou George Ten.</p>
    <p>— Você é o último dos modelos JG, George. Seu cérebro é o mais complicado que até hoje planejamos, de certa maneira mais sutilmente complicado do que o das velhas Máquinas Gigantes. Ele é aberto, e, começando com uma base humana, poderá, isto é, sem dúvida alguma crescerá em qualquer direção. Permanecendo sempre dentro das intransponíveis fronteiras das Três Leis, não obstante você vir a se tomar completamente não humano em seu pensamento.</p>
    <p>— Você conhece suficientemente seres humanos para abordar racionalmente esse problema? Sobre a história deles? A psicologia deles?</p>
    <p>— Claro que não. Mas você poderá aprender tão rapidamente quanto é capaz.</p>
    <p>— Terei ajuda, Sr. Harriman?</p>
    <p>— Não. Este é um assunto inteiramente entre nós dois. Ninguém mais sabe disto e você não deve mencionar este projeto a nenhuma pessoa, seja na U.S. Robots, seja lá onde for.</p>
    <p>George Ten disse: — Será que estamos fazendo alguma coisa errada, Sr. Harriman, para o senhor querer manter isto em segredo?</p>
    <p>— Não, mas uma solução robô não será aceita precisamente por ser originalmente robótica. Qualquer solução que você tenha a sugerir recairá sobre mim; e, se me parecer válida, eu a apresentarei. Jamais alguém saberá que ela proveio de você.</p>
    <p>— A luz do que você disse anteriormente, este é o procedimento correto... — disse George Ten, calmamente. — Quando começo?</p>
    <p>— Agora mesmo. Vou tomar as providências para que você tenha todos os filmes necessários para o exame da questão.</p>

    <h4>1a.</h4>

    <p>Harriman sentou-se, sozinho. No interior de seu escritório, artificialmente iluminado, não havia indicação de que lá fora escurecera. Ele não percebia, na verdade, que já se tinham passado três horas desde que conduzira George Ten de volta a seu cubículo, lá o deixando com os primeiros filmes de referência.</p>
    <p>Estava agora sozinho, simplesmente com o fantasma de Susan Calvin, a brilhante roboticista que, praticamente sem ajuda de ninguém, fizera um robô positrônico evoluir de um brinquedo maciço para o mais delicado e versátil instrumento; tão delicado e versátil, que o homem não ousava usá-lo, por inveja e receio.</p>
    <p>Agora já fazia mais de um século que ela falecera. O problema do complexo de Frankenstein existira no tempo <i>dela</i>, e ela nunca o resolvera. Nunca ela o tentara resolver, porque não havia necessidade. Nos tempos de Susan, a robótica se desenvolvera de acordo com as necessidades da exploração espacial.</p>
    <p>Havia sido o próprio sucesso dos robôs que diminuira a necessidade que os homens tinham deles, e que tinha deixado Harriman, nestes últimos tempos...</p>
    <p>Porém, Susan Calvin podería ter se voltado para os robôs em busca de auxílio. Seguramente, podería...</p>
    <p>E lá ficou ele sentado, enquanto a noite decorria.</p>

    <h4>2.</h4>

    <p>Maxwell Robertson era o maior acionista da U.S. Robots, sendo assim seu superintendente. Sua aparência não era, de forma alguma, de impressionar. Já estava bem na meia-idade, um tanto rechonchudo. E tinha o costume de ficar mordendo o canto direito de seu lábio inferior quando estava perturbado.</p>
    <p>De qualquer maneira, em suas duas décadas de relacionamento com pessoas do governo, ele tinha desenvolvido uma maneira de lidar com elas. Tendia a usar a delicadeza, cedendo, sorrindo, e sempre tentando ganhar tempo.</p>
    <p>Mas as coisas estavam ficando difíceis — e uma das grandes razões para elas se tornarem difíceis era Gunnar Eisenmuth. Na série de Conservadores Globais, cujo poder era inferior somente ao do Executivo Global no decorrer do século anterior. Eisenmuth cortava caminho, cada vez mais, para a difícil e cinzenta área de um compromisso. Ele era o primeiro Conservador não nascido nos Estados Unidos e, se bem que não pudesse ser demonstrado de maneira alguma que o arcaico nome da U.S. Robots despertava sua hostilidade, todos na U.S. Robots acreditavam nisso.</p>
    <p>Houvera uma sugestão — de alguma forma a primeira naquele ano — ou naquela geração — de que o nome da empresa fosse mudado para World Robots, mas Robertson nunca consentiría isto. Originalmente, a empresa tinha sido constituída com capital americano, cérebros americanos e trabalho, americano, e a despeito de a empresa ter tido atuação mundial, por seu próprio escopo, por sua própria natureza, o nome teria de testemunhar a origem da empresa enquanto estivesse sob o controle dele, Maxwell.</p>
    <p>Eisenmuth era um homem alto, com um rosto triste e alongado, com textura e feições grosseiras. Dizia “Global” com um pronunciado acento americano, se bem que nunca tivesse estado nos Estados Unidos antes de assumir o cargo.</p>
    <p>— Para mim, isto parece perfeitamente claro, Sr. Robertson. Não há dificuldade. Os produtos de sua empresa são sempre alugados, nunca vendidos. Se não há mais necessidade do que é de sua propriedade e que está alugado na Lua, cabe ao senhor receber de volta os produtos e transferi-los.</p>
    <p>— Sim, Conservador, mas onde? Seria contra a lei trazê-lo de volta à Terra sem permissão governamental e ela foi negada.</p>
    <p>— Não seriam úteis para vocês aqui na Terra. Pode levá-los para Mercúrio ou para os asteróides.</p>
    <p>— E que é que faríamos com eles por lá?</p>
    <p>Eisenmuth ficou carrancudo. — Os inteligentes homens de sua empresa.pensarão numa solução.</p>
    <p>Robertson meneou .a cabeça. — Isso representaria uma enorme perda para a U. S. Robots.</p>
    <p>— Receio que sim — retrucou Eisenmuth, sem se deixar demover. — Estou sabedor de que a U.S. Robots há vários anos tem tido prejuízos.</p>
    <p>— Em grande parte, Conservador, devido às restrições governamentais.</p>
    <p>— O senhor precisa ser realista, Sr. Robertson. Bem sabe que o clima da opinião pública é cada vez mais contra os robôs.</p>
    <p>— O que está muito errado, Conservador.</p>
    <p>— Mas assim são as coisas. Seria mais inteligente encerrar as atividades da empresa. Naturalmente que isto é uma mera sugestão.</p>
    <p>— Mas suas sugestões têm força, Conservador. Será necessário dizer-lhe que nossas Máquinas, um século atrás, resolveram a crise ecológica?</p>
    <p>— Estou certo de que a humanidade está grata, mas isso foi há cem anos atrás. Vivemos agora em aliança com a natureza, mesmo</p>
    <p>que isto de vez em quando seja desconfortável, e o passado está obscurecido.</p>
    <p>— Está querendo dizer... pelo que fizemos ultimamente pela humanidade?</p>
    <p>— Acredito que sim.</p>
    <p>— Mas de maneira alguma se pode crer que encerramos de uma hora para outra nossas atividades; não sem enormes prejuízos. Precisamos de tempo.</p>
    <p>— Quanto?</p>
    <p>— Quanto tempo pode nos dar?</p>
    <p>— Não depende de mim.</p>
    <p>Delicadamente, Robertson disse: — Estamos.sozinhos. Não podemos brincar. Quanto tempo pode nos dar?</p>
    <p>A expressão de Eisenmuth era a de uma pessoa refugiando-se em si mesma, para cálculos bem lá no seu íntimo. — Penso que pode contar com uns dois anos. Serei franco: o governo global pretende assumir o controle da U. S. Robots e pôr você para fora, se você não se retirar antes. Mais ou menos, é isto que pretendem. E, a não ser que haja uma enorme mudança na opinião pública, coisa de que duvido muito... — E mexeu a cabeça para um lado e para o outro.</p>
    <p>— Dois anos, então — disse Robertson delicadamente.</p>

    <h4>2a.</h4>

    <p>Robertson sentara-se, sozinho. Não havia propósito no que pensava, e seu raciocínio acabara virando retrospecção. Quatro gerações de Robertsons tinham dirigido a empresa, sendo que nenhum deles era roboticista. Tinha havido homens como Lanning e Bogert, e, acima de tudo, <i>acima</i> de todos, Susan Calvin, que tinha feito da U. S. Robots o que ela era. Era certo, contudo, que os quatro Robertsons tinham propiciado o clima que tornara possível o trabalho deles.</p>
    <p>Sem a U. S. Robots, o Século Vinte e Um teria caminhado para um crescente desastre. Isto não se devia às Máquinas que, por uma geração, haviam guiado a humanidade em meio às corredeiras e aos escolhos da história.</p>
    <p>E, para isto, davam-lhe agora dois anos. Que se poderia fazer, em dois anos, para vencer os insuperáveis preconceitos da humanidade? Ele não sabia.</p>
    <p>Esperançosamente, Harriman falara sobre novas idéias, sem entrar em detalhes, porém. E pela simples razão de que Robertson não entendería patavina.</p>
    <p>De qualquer forma, porém, que poderia Harriman fazer? Que é que alguém jamais tentara fazer contra a intensa antipatia que as pessoas sentiam contra a U.S. Robots?! Nada...</p>
    <p>Robertson mergulhou numa sonolência que nenhuma inspiração lhe trouxe.</p>

    <h4>3.</h4>

    <p>— Agora você tem tudo, George Ten — disse Harriman. — Está de posse de tudo quanto penso que seja aplicável ao problema. No que diz respeito à informação pura propriamente dita, você já armazenou mais em sua memória sobre os seres humanos e seu modo de ser, no passado e no presente, do que eu ou qualquer ser humano poderia ter feito.</p>
    <p>— E bem provável que seja assim.</p>
    <p>— Você acha que precisa de alguma coisa mais?</p>
    <p>— No que tange a informações, não vejo “furos” evidentes. Pode ser que, nos limites, haja assuntos em que ainda não cogitamos. Não sei dizer. Mas isso sucedería por maior que fosse o círculo de informações que eu recebesse.</p>
    <p>— É verdade. Nem nós teremos mais tempo para recolher novas informações. Robertson me falou que temos apenas dois anos e a quarta parte desses dois anos já se escoou... Tem algo a sugerir?</p>
    <p>— Por ora nada, Sr. Harriman. Preciso sopesar as informações e para tanto preciso de ajuda.</p>
    <p>— Minha?</p>
    <p>— Não, não particularmente do senhor, porque o senhor é um ser humano altamente qualificado e o que quer que me diga terá a força parcial de uma ordem que poderá inibir minhas deliberações. E também não é ajuda de nenhum outro ser humano, pela mesma razão e, especialmente, porque me proibiu de me comunicar com qualquer ser humano.</p>
    <p>— Mas, neste caso, George, que ajuda?</p>
    <p>— De outro robô, Sr. Harriman.</p>
    <p>— Que outro robô?</p>
    <p>— Foram construídos outros robôs da série JG. Sou o JG-10 e, portanto, o décimo.</p>
    <p>— Os primeiros não serviam para nada, eram experimentais...</p>
    <p>— Existe George Nine.</p>
    <p>— Está certo, mas para que serviría ele? Descontando certas coisas que faltam a ele, parece-me muito com você. Você é consideravelmente mais versátil do que ele.</p>
    <p>— Eu sei disso — falou George Ten, meneando com gravidade a cabeça. — Não obstante, assim que eu crie uma linha de pensamento, o mero fato de eu criá-la faz com que a aprove, sendo-me difícil pô-la de lado. Se eu puder, após desenvolver uma linha de pensamento, exprimi-la a George Nine, ele a consideraria sem a ter criado. Destarte, ele a encararia sem preconceitos. Poderia ver faltas e falhas que eu não vejo.</p>
    <p>Harriman sorriu. — Em outras palavras, duas cabeças pensam melhor que uma, hem, George?</p>
    <p>— Se com isso, Sr. Harriman, o senhor quer dizer duas pessoas pensando com uma cabeça só, sim.</p>
    <p>— Certo. Quer mais alguma coisa?</p>
    <p>— Sim, algo mais do que filmes. Ponderei muito sobre os seres humanos e seu mundo. Tenho observado as pessoas aqui na U. S. Robots e posso aquilatar minha interpretação do que tenho visto confrontada com minhas impressões sensoriais. O mesmo não se aplica ao mundo físico. Nunca o vi, mas a idéia que tenho basta para me dizer que de maneira alguma o que aqui me rodeia representa o mundo físico. Gostaria de vê-lo.</p>
    <p>— O mundo físico? — Harriman pareceu atordoado com a grandeza daquele pensamento, por um momento. — Não está querendo me sugerir que eu leve você para fora das instalações da U. S. Robots?</p>
    <p>— Sim, essa é minha sugestão.</p>
    <p>— Isso sempre foi ilegal. E, no clima em que está a opinião pública hoje em dia, seria fatal.</p>
    <p>— Isso se formos detectados. Não estou sugerindo que me leve a uma cidade ou mesmo a uma casa. Gostaria de ver algumá região aberta, sem seres humanos.</p>
    <p>— Isso também é ilegal.</p>
    <p>— Se formos apanhados. Mas precisamos ser?...</p>
    <p>— Mas será que isso é absolutamente indispensável, George? — perguntou Harriman.</p>
    <p>— Não sei dizer, mas me parece que seria útil.</p>
    <p>— Em que está pensando?</p>
    <p>George Ten pareceu hesitar. — Não sei dizer, mas me parece que alguma coisa poderia me vir à mente se fossem reduzidas certas áreas de incerteza</p>
    <p>— Bem, deixe-me pensar no caso. E, entrementes, vou-me informar sobre George Nine é providenciar para que vocês dois ocupem o mesmo cubículo. Pelo menos isto pode ser feito sem problemas.</p>

    <h4>3a.</h4>

    <p>George Ten sentou-se, sozinho.</p>
    <p>Aceitava afirmações experimentalmente, reunia-as e esboçava uma conclusão, repetidas vezes. E, a partir das conclusões, elaborava outras afirmações, que aceitava e testava, e nas quais achava uma contradição, rejeitando-as em seguida; ou não achava contradição e passava adiante, experimentalmente.</p>
    <p>Não se sentia entusiasmado por nenhuma das conclusões a que chegara, nem surpresa ou satisfação; apenas um tom de mais ou menos.</p>

    <h4>4.</h4>

    <p>Mesmo após terem aterrissado silenciosamente na propriedade de Robertson, não diminuira visivelmente a tensão de Harriman.</p>
    <p>Robertson tinha assinado, como ratificação, a ordem, pondo à disposição o dinafólio e a silenciosa aeronave, que com a mesma facilidade se movia na horizontal e na vertical, era suficientemente ampla para suportar o peso de Harriman, de George Ten, e, logicamente, também o do piloto.</p>
    <p>(O próprio dinafólio era uma das conseqüências da invenção, catalisada pela Máquina, da micropilha protônica, que fornecia energia isenta de poluição, em pequenas doses. Para o conforto humano, nada de igual importância tinha sido feito; não obstante, não havia gratidão para com a U. S. Robots. Os lábios de Harriman se crisparam quando ele se lembrou disso.)</p>
    <p>O vôo entre as instalações da fábrica e a propriedade de Robertson era a parte arriscada. Tivessem sido detidos, e a presença de um robô a bordo teria significado um monte de complicações. Na volta, seria a mesma coisa. Quanto à permanência na propriedade, poder-se-ia argumentar — esse argumento <i>seria usado</i> — que aquela era parte dos terrenos da U. S. Robots, e nesses terrenos, adequadamente supervisionados, os robôs poderíam muito bem permanecer.</p>
    <p>O piloto olhou para trás e seus olhos se detiveram com prudente brevidade, em George Ten. — Vai descer mesmo, Sr. Harriman?</p>
    <p>— Sim.</p>
    <p>— O robô também?</p>
    <p>— Claro. — E acrescentou, um tanto ironicamente: — Não vou deixar você sozinho com ele...</p>
    <p>Primeiro desceu George Ten. Harriman seguiu-o. Tinham descido no folioporto e o jardim não estava muito longe. Era uma verdadeira exposição” e Harriman desconfiava que Robeftson fazia uso de hormônios juvenis para controlar a vida dos insetos, sem dar muita atenção a fórmulas ambientais.</p>
    <p>— Venha, George — disse Harriman. — Vou lhe mostrar.</p>
    <p>Juntos, caminharam na direção do jardim.</p>
    <p>— É um pouco como eu imaginava — afirmou George. — Meus olhos não são planejados para detectarem diferenças de comprimento de onda, de forma que não posso distinguir objetos diferentes por si sós.</p>
    <p>— Confio em que você não ficará zangado por ser cego a cores. Precisávamos de muitas trilhas positrônicas para seu senso de julgamento e fomos incapazes de desperdiçar quaisquer trilhas para a sensação de cor. No futuro — se houver futuro...</p>
    <p>— Eu compreendo, Sr. Harriman. Subsistem diferenças bastantes para que eu me aperceba de que há aqui muitas formas diferentes de vida vegetal.</p>
    <p>— Sem a menor dúvida. Dúzias delas.</p>
    <p>— Cada uma das quais, biologicamente co-igual ao homem.</p>
    <p>— Sim, cada qual é uma espécie separada. Há milhões de espécies de criaturas vivas.</p>
    <p>— Das quais os seres humanos são apenas uma espécie.</p>
    <p>— Entretanto, de longe, os mais importantes dentre os seres vivos.</p>
    <p>— E para mim, Sr. Harriman. Mas estou falando no sentido biológico.</p>
    <p>— Entendo.</p>
    <p>— De forma que, encarada através de todas as suas manifestações, a vida é incrivelmente complexa.</p>
    <p>— Sim, eis aí o ponto crucial do problema. Aquilo que o homem faz por seus próprios desejos, para seu próprio conforto, afeta a totalidade do complexo dos seres vivos, a ecologia, e seus ganhos a curto prazo trazem desvantagens a longo prazo. As máquinas nos ensinaram a construir uma sociedade humana que minimizaria as desvantagens, mas o quase desastre do Século Vinte e Um fez com que a humanidade passasse a desconfiar das inovações. Isto, acrescentado ao temor especial para com os robôs...</p>
    <p>— Compreendo... Estou certo de que isto seja um exemplo de vida animal.</p>
    <p>— É um esquilo, uma das muitas espécies de esquilo.</p>
    <p>A cauda do esquilo se agitou quando ele passou para o outro lado da árvore.</p>
    <p>— E isto — disse George, enquanto seu braço se movia com grande rapidez — é mesmo uma coisinha pequena. — Ele tinha a “coisinha” em seus dedos e a examinava detidamente.</p>
    <p>— É um inseto, uma espécie de besouro. Há milhares de espécies de besouros.</p>
    <p>— Sendo que cada um dos besouros é tão vivo quanto você e o esquilo?</p>
    <p>— É um organismo tão completo e independente como qualquer outro, no conjunto total da ecologia. Há organismos menores ainda: muitos são pequenos demais para serem vistos.</p>
    <p>— E isto é uma árvore, não é mesmo? Ela é dura ao toque...</p>

    <h4>4a.</h4>

    <p>O piloto estava sentado, sozinho. Bem que ele gostaria de esticar as pernas, mas um sombrio senso de segurança o fazia manter-se no aerofólio., Se aquele robô escapasse do controle, decolaria imediatamente. Mas, como saber se ele estava fora de controle?</p>
    <p>Tinha visto muitos robôs. Inevitável, visto que era o piloto particular do Sr. Robertson. Todavia, sempre os robôs estavam nos laboratórios e nos depósitos a que pertenciam, com muitos especialistas por perto.</p>
    <p>Era verdade: o Dr. Harriman era um especialista. Ninguém melhor que ele, diziam. Mas, um robô aqui, estava era num lugar onde nenhum robô deveria estar: na Terra, num espaço aberto, livre para se mover... Ele, o piloto, não arriscaria seu bom emprego contando a quem quer que fosse o que presenciava — mas que não estava certo, não esiava.</p>

    <h4>5.</h4>

    <p>George Ten disse: — Em termos do que ora estou vendo, os filmes que vi eram bem exatos. Já terminou os que selecionei pára você; Nine?</p>
    <p>— Sim — disse George Nine. Os dois robôs estavam sentados hirtos, face a face, joelho a joelho, como uma imagem e seu reflexo. Num relance, o Dr. Harriman poderia dizer quem era um e quem era outro, pois estava familiarizado com as menores diferenças no desenho físico. Mesmo que não pudesse vê-los, mas pudesse falar-lhes, ainda poderia distinguir um do outro, ainda que com um pouco menos de certeza, pois as respostas de George Nine seriam sutilmente diferentes das produzidas pelos modelos positrônicos das trilhas do cérebro de George Ten, que era substancialmente mais intricado.</p>
    <p>— Neste caso — disse George Ten — dê-me suas reàções ao que vou lhe dizer. Primeiro: os seres humanos temem os robôs e não crêem neles porque os encaram como competidores. Como se pode impedir isto?</p>
    <p>— Reduzindo-se o senso de competição — falou George Nine — modelando-se o robô de uma forma diferente da do ser humano.</p>
    <p>— Assim mesmo, a essência de um robô é sua reprodução positrônica da vida. Uma réplica da vida numa forma não associada a ela, poderia despertar horror.</p>
    <p>— Existem dois milhões de formas de espécies de vida. Por que não escolher uma dessas espécies como forma em vez de a de um ser humano?</p>
    <p>— Qual dessas espécies?</p>
    <p>Os processos de pensamento de George Nine funcionaram sem ruído durante uns três segundos. — Uma forma suficientemente larga para conter um cérebro positrônico, mas nenhuma que possua associações desagradáveis para os seres humanos.</p>
    <p>— Nenhuma forma de vida terrestre possui uma caixa craniana suficientemente grande para um cérebro positrônico, a não ser a do elefante, que não vi, mas que é descrito como sendo muito grande e, portanto, assustador para o homem. Como você enfrentaria este dilema?</p>
    <p>— Vamos imitar uma forma de vida que não seja maior do que um homem mas com uma caixa craniana maior.</p>
    <p>George Ten disse: — Então, um cavalinho, ou um cachorrão, digamos? Tanto os cavalos como os cachorros têm antigas histórias de associação com os seres humanos.</p>
    <p>— Então está bem.</p>
    <p>— Mas, vejamos... Um robô com um cérebro positrônico imitaria a inteligência humana. Se houvesse um cavalo ou um cachorro que pudesse falar e raciocinar como um ser humano, também havería competitividade. Os seres humanos poderíam até ficar mais descrentes e irritados ainda éom esta inesperada competição do que eles consideram uma forma inferior de vida.</p>
    <p>— Façamos um cérebro positrônico menos complexo e o robô menos inteligente — falou George Nine.</p>
    <p>— O ponto mais complexo do caso do cérebro positrônico está nas Três Leis. Um cérebro menos complexo não poderia possuir as Três Leis em sua plenitude.</p>
    <p>Imediatamente, George Nine replicou: — Isso não pode ser feito!</p>
    <p>— Também cheguei a este beco sem saída — afirmou George Ten. — Quer dizer que isto, então, não é uma peculiaridade de minha linha de pensamento, de minha maneira de pensar... Vamos começar tudo de novo... Em que condições a Terceira Lei não seria necessária?</p>
    <p>Como se a pergunta fosse difícil e perigosa, George Nine se agitou. De qualquer forma, acabou dizendo: — Se um robô nunca fosse colocado numa posição de perigo para si mesmo ou se um robô fosse tão facilmente substituível, que não fizesse diferença se ele fosse destruído ou não.</p>
    <p>— E em que condições poderia a Segunda Lei não ser necessária?</p>
    <p>A voz de George Nine soou um tanto roufenha. — Se um robô fosse planejado para responder automaticamente a certos estímulos com respostas fixas e se não esperassem mais nada dele, de forma que jamais fosse necessário lhe dar uma ordem.</p>
    <p>— E em que condições... — aqui, George Ten fez uma pausa — poderia a Primeira Lei não ser necessária?</p>
    <p>Foi mais longa, desta vez, a pausa de George Nine, e suas palavras vieram num sussurro: — Se as respostas fixas fossem de natureza tal que jamais acarretassem perigo para seres humanos.</p>
    <p>— Imagine, então, um cérebro positrônico que apenas guia umas poucas respostas para certos estímulos, fabricado com simplicidade e a baixo custo, de forma a não requerer as Três Leis. Quão grande precisaria ser um cérebro assim?</p>
    <p>— O tamanho não é uma questão primordial. Dependendo das respostas exigidas, poderia pesar uns cem gramas, um grama, um miligrama.</p>
    <p>— Seus pensamentos coincidem com os meus. Vou falar com o Dr. Harriman.</p>

    <h4>5a.</h4>

    <p>George Nine ficou sentado, a sós. Vezes e mais vezes pensou nas perguntas e nas respostas. Não havia como modificá-las. Não obstante, pensar num robô de qualquer espécie, de qualquer tamanho, de qualquer formato, destinado a qualquer finalidade, sem as Três Leis, lhe dava uma sensação esquisita, de perda de alguma coisa.</p>
    <p>Estava com dificuldade para se mover. Com toda segurança, George Ten devia estar com uma reação similar. Mesmo assim, conseguira erguer-se facilmente de seu assento.</p>

    <h4>6</h4>

    <p>Fazia um ano e meio que Robertson e Eisenmuth tinham estado trancafiados, sozinhos, a conversar. Entrementes, os robôs tinham sido retirados da Lua e todas as extensas atividades daU. S. Robots tinham definhado. Todo o dinheiro que Robertson tinha sido capaz de arranjar tinha sido investido no quixotesco investimento de Harriman.</p>
    <p>Era o último trunfo jogado, aqui em seu próprio jardim. Um ano antes, Harriman tinha trazido George Ten para cá, o último robô completo fabricado pela U.S. Robots. Agora, aqui estava Harriman, com algo mais...</p>
    <p>Harriman parecia irradiar confiança. Conversava bem à vontade com Eisenmuth, e Robertson bem que gostaria de saber se Harriman sentia mesmo a confiança que parecia ter. Devia sentir, sim. Por sua experiência, Robertson sabia que Harriman não era um ator.</p>
    <p>Eisenmuth deixou Harriman, sorrindo, e dirigiu-se a Robertson. Imediatamente, o sorriso de Eisenmuth se apagou. — Bom dia, Robertson — disse ele. — Que é que seu homem pretende?</p>
    <p>— Isto é assunto dele — disse Robertson calmamente</p>
    <p>Harriman gritou: — Estou pronto, Conservador.</p>
    <p>— Pronto com o quê, Harriman?</p>
    <p>— Com meu robô, senhor.</p>
    <p>— Seu robô? — perguntou Eisenmuth. — Você tem um robô aqui? — Olhou em tomo severamente, com um ar de desaprovação e que tinha uma mescla de curiosidade.</p>
    <p>— Isto é propriedade da U. S. Robots, Conservador. Pelo menos, assim a consideramos.</p>
    <p>— E onde está o robô, Dr. Harriman?</p>
    <p>— Em meu bolso, Conservador — disse Harriman alegremente.</p>
    <p>O que saiu de um amplo bolso de jaqueta era um jarrinho de vidro.</p>
    <p>— Isto? — perguntou Eisenmuth incrédulo.</p>
    <p>— Não,Conservador. Isto! — falou Harriman.</p>
    <p>Do outro bolso saiu um objeto de uns doze centímetros de comprimento e mais ou menos com a aparência de um pássaro. Em lugar do bico, havia um tubo estreito; os olhos eram grandes e a cauda era um tubo de escape.</p>
    <p>As espessas sobrancelhas de Eisenmuth se ergueram juntas. — Está querendo fazer uma demonstração a sério de alguma coisa, Dr. Harriman, ou está ficando maluco?</p>
    <p>— Seja paciente por alguns minutos, Conservador. Um robô, por ter forma de pássaro, nem por isso deixa de ser um robô. E o cérebro positrônico que ele possui não é menos delicado para um ser minúsculo. Este jarrinho que estou segurando contém moscas-das-frutas. Contém cinqüenta moscas, que serão liberadas.</p>
    <p>— E...</p>
    <p>— O pássaro-robô as apanhará. Querem me dar a honra, senhores?...</p>
    <p>Harriman estendeu a jarra para Eisenmuth, que fixou nela os olhos, depois nos circunstantes — alguns funciona'rios da U.S. Robots, outros, seus próprios auxiliares. Pacientemente, Harriman aguardava.</p>
    <p>Eisenmuth abriu a jarra; depois, sacudiu-a.</p>
    <p>Delicadamente, Harriman disse ao pássaro-robô que repousava na palma da sua mão direita: — Vá!</p>
    <p>E ele se foi. Era um silvo no ar, sem o movimento de asas: apenas o funcionamento de uma micropilha protônica incomumente diminuta.</p>
    <p>Ele podia ser visto, ora sim, ora não, numa pequena parada momentânea e depois zunia novamente. Por todo o jardim voava, numa complicada evolução, e de novo voltava para a mão de Harriman, tenuamente aquecido. Aparecia também na palma uma capsulazinha, como se fosse um excremento de pássaro.</p>
    <p>Harriman disse: — Seja bem-vindo para estudar o pássaro-robô, Conservador, e para arranjar as demonstrações que forem de seu agrado. O fato é que este pássaro apanhará, sem errar, moscas de fruta, somente estas, as da espécie <i>Drosophila melanogaster</i>; ele as apanhará, as matará e as esmagará, para serem jogadas fora.</p>
    <p>Eisenmuth estendeu a mão e cautelosamente tocou o pássaro-robô. — E daí, Sr. Harriman? Prossiga, por favor.</p>
    <p>— Não podemos exercer um controle efetivo sobre os insetos sem pormos em risco a ecologia — falou Harriman. — Os inseticidas químicos atacam demais; os hormônios juveniles são limitados demais. O pássaro-robô, contudo, pode preservar amplas áreas, sem que sejam destruídas. Os pássaros-robôs podem ser tão específicos quanto o desejarmos — um para cada espécie. Eles julgam pelo tamanho, pela forma, pela cor, pelo som, pelo modo de comportamento. É admissível até que se valham da detecção molecular — em outras palavras, o cheiro.</p>
    <p>Eisenmuth disse: — Mesmo assim ainda estaríamos interferindo na ecologia. As moscas das frutas têm um ciclo natural de vida que seria rompido.</p>
    <p>— Em pequena escala. Estamos acrescentando ao ciclo de vida da mosca da fruta um inimigo natural, que não pode fracassar. Se escassear o número de moscas-das-frutas, simplesmente o pássaro-robô não fará nada. Ele não se multiplica, não procura outros alimentos, não desenvolve hábitos indesejáveis por si mesmo. Não faz nada.</p>
    <p>— Ele pode ser chamado de volta?</p>
    <p>— Lógico que sim. Podemos fabricar animais-robô para eliminarmos qualquer peste. Neste sentido, podemos fabricar animais-robô para finalidades construtivas, de acordo com os ditames ecológicos. Se bem que não anteciparemos a necessidade, não há nada de inconcebível na necessidade de abelhas-robô, concebidas para fertilizar plantas específicas, ou minhocas-robô para misturar o solo. O que quer que deseje...</p>
    <p>— Mas... por quê?</p>
    <p>— Para fazer o que nunca fizemos antes. Para ajustar a ecologia a nossas necessidades, fortalecendo suas partes, êm vez de dilacerá-las... Não está vendo? Desde que as Máquinas puseram fim à crise ecológica, a humanidade tem vivido numa desassossegada trégua com a natureza, receosa de se mover-nesta ou naquela direção. Isto nos tem estupidificado, fazendo da humanidade um covarde intelectual, de forma que ela começa a descrer de qualquer avanço científico, de qualquer mudança.</p>
    <p>Com um tom de hostilidade, Eisenmuth falou: — Quer dizer que isto é o que você nos oferece, em troca de uma permissão para continuar seu programa de robôs — refiro-me aos comuns, com forma humana?</p>
    <p>Com um gesto violento, Harriman respondeu: — Não! Isto acabou. Já preencheu suas finalidades. Ensinou-nos bastante sobre os cérebros positrônicos para nos tomar possível atulhar de trilhas um minúsculo cérebro e assim chegarmos ao pássaro-robô. Podemos agora nos voltar para coisas assim e prosperarmos o suficiente. A U. S. Robots fornecerá o <i>know-how</i> e a habilidade necessários e trabalharemos em estreita cooperação com o Departamento de Conservação Global. Prosperaremos, o senhor também prosperará. A humanidade prosperará.</p>
    <p>Eisenmuth estava silencioso, a pensar. Quando tudo terminou...</p>

    <h4>6a.</h4>

    <p>Eisenmuth sentou-se, sozinho.</p>
    <p>Ele estava acreditando. Dentro dele havia um excitamento bem-vindo. Ainda que a U. S. Robots fosse as mãos, o cérebro a dirigi-la seria o governo. Ele próprio seria o cérebro diretor.</p>
    <p>Se permanecesse no cargo por mais cinco anos, como de fato podería, isto seria tempo bastante para ver aceito o apoio robôtico à ecologia; mais dez anos, e seu próprio nome estaria vinculado indissoluvelmente àquele programa.</p>
    <p>Querer ser lembrado por uma grande e meritória revolução na condição humana e do planeta seria uma desonra?</p>

    <h4>7</h4>

    <p>Desde o dia da demonstração, Robertson não havia mais sido visto nas suas dependências da U. S. Robots. Em parte, a razão eram suas conferências mais ou menos constantes na Global Executive Mansion. Felizmente, Harriman estivera com ele, mais tempo até do que ele querería que o outro estivesse, pois, se deixado a si mesmo, Robertson são sabería o que dizer.</p>
    <p>O restante da razão para não ter estado na U. S. Robots era que ele não queria estar. Com Harriman, ele estava agora em sua própria casa.</p>
    <p>Sentia um temor ilógico por Harriman, cuja capacidade em robôs nunca fora questionada. Mas, de um golpe, o fato é que Harriman salvara a U.S. Robots de uma extinção certa. E, de certa maneira, Robertson o sentia, aquilo não era propriamente... próprio de Harriman. E, não obstante...</p>
    <p>Disse: — Você não é supersticioso, Harriman, não é mesmo?</p>
    <p>— Em que sentido, Sr. Robertson?</p>
    <p>— Não acredita que quem morre deixa uma certa aura?...</p>
    <p>Harriman lambeu os lábios. Num certo sentido, não tinha nem por que perguntar. — O senhor quer dizer Susan Calvin, sire?</p>
    <p>— Sim, claro que sim — disse Robertson, hesitante. — Nosso negócio, agora, é fazer vermes, pássaros e besouros. Que diria <i>ela?</i> Sinto-me degradado.</p>
    <p>Harriman fez um visível esforço para não rir. — Um robô é um robô, sire. Verme ou homem, agirá conforme for dirigido e trabalhará em prol dos seres humanos, e é isto que importa.</p>
    <p>Irritadiço, o outro redargüiu: — Não, não é assim. Não consigo acreditar nisso.</p>
    <p>— Mas assim <i>é</i>, Sr. Robertson — falou Harriman, com franqueza. — Você e eu vamos criar um mundo, que, pelo menos, começará a levar em consideração cérebros positrônicos de <i>alguma</i> espécie. Um homem comum poderá temer um robô que pareça uma pessoa e que pareça suficientemente inteligente para substituí-lo, mas não terá medo de um robô que se pareça com um pássaro e que outra coisa não faz senão comer moscas, em benefício dele, homem. Eventualmente, então, depois que os homens deixarem de ter medo de alguns robôs, pararão de ter medo de qualquer robô. Estarão tão acostumados com um pássaro-robô, com uma abelha-robô e com um robô-verme, que um robô-homem só os espantará como um prolongamento.</p>
    <p>Robertson olhou o outro acerbamente. Pôs as mãos atrás das costas e caminhou o comprimento da sala com passos nervosos e rápidos. Caminhou de volta e olhou de novo para Harriman. — É isto que você tem estado a planejar?</p>
    <p>— Sim. E mesmo que desmantelemos todos os nossos robôs humanóides, poderemos conservar alguns de nossos modelos experimentais mais avançados e continuar a planejar outros, adicionais, mais avançados ainda, para estarmos prontos para o dia que, seguramente, há de vir.</p>
    <p>— O acordo, Harriman, é que não mais construamos robôs humanóides.</p>
    <p>— E não construiremos. Nada há que diga que estamos impedidos de manter uns poucos dos que já construímos, contanto que não deixem a fábrica. Nada há que diga que não podemos planejar, no papel, cérebros positrônicos, ou preparar modelos para testes.</p>
    <p>— Mesmo assim, como explicaremos nosso procedimento? É seguro que nos apanharão.</p>
    <p>— Se formos, então podemos explicar que assim estamos procedendo para desenvolver princípios que tornarão possível preparar microcérebros mais complexos para os novos animais-robô que estamos fabricando. Estaremos até dizendo a verdade.</p>
    <p>Robertson resmungou: — Deixe-me dar uma voltinha. Vou meditar sobre isto. Não, fique aqui. Quero pensar sozinho.</p>

    <h4>7a.</h4>

    <p>Harriman ficou sozinho. Estava em ebulição: lógico que a coisa funcionaria. Não havia como interpretar erradamente a ansiedade com que, uns após os outros, os funcionários governamentais haviam se apoderado do programa, uma vez ele exposto.</p>
    <p>Como era possível que jamais alguém na U. S. Robots tivesse pensado em algo assim? Nem mesmo a grande Susan Calvin jamais pensara em cérebros positrônicos em termos de outras criaturas vivas que não os seres humanos.</p>
    <p>Agora, porém, a humanidade faria a necessária retirada dos robôs humanóides, uma retirada temporária, que conduziría a um retorno em que, por fim, o temor seria abolido. E, então, com a ajuda e a parceria de um cérebro positrônico toscamente equivalente ao do próprio homem, existindo apenas (graças às Três Leis) para servir ao homem, e apoiado por uma ecologia baseada em robôs, também, que é que a raça humana não podería realizar?!</p>
    <p>Por um momento, ele lembrou que fora George Ten que explicara a natureza e a finalidade da ecologia apoiada em robôs. Pôs, então, o pensamento de lado, irritado. George Ten produzira a resposta porque ele, Harriman, lhe ordenara que assim fizesse e lhe fornecera os dados e a ambientação necessários. O crédito não era de George Ten mais do que seria de uma régua de cálculo.</p>

    <h4>8.</h4>

    <p>George Ten e George Nine estavam colocados um ao lado do outro, nenhum dos dois se movendo. Assim permaneceram meses a fio, entre as ocasiões em que Harriman os ativava para consultas. Talvez assim ficassem por muitos anos, imaginava George Ten, desapaixonaüamente.</p>
    <p>Certamente que a micropilha protônica continuaria a lhes dar força e continuaria a manter as trilhas do cérebro positrônico porh o mínimo de intensidade necessária para mantê-los operativos.. Assim continuaria a ser durante todos os períodos futuros de inatividade.</p>
    <p>A situação era um tanto ou quanto análoga à que poderia ser descrita, no caso de seres humanos, como de sono, sem haver sonhos, contudo. A consciência de George Ten e de George Nine era limitada, lenta e espasmódica, mas o que quer que nela houvesse era do mundo real.</p>
    <p>Ocasionalmente, podiam falar um com o outro, em sussurros que mal se ouviam, ora uma palavra, ora uma sílaba, de tempos em tempos, sempre que, ao acaso, os impulsos positrônicos se intensificassem por um breve tempo acima do limiar necessário. Para cada um deles, parecia uma conversa em seqüência, levada a efeito numa bruxuleante passagem de tempo.</p>
    <p>— Por-que é que estamos assim? — murmurava George Nine.</p>
    <p>— De outra maneira, os seres humanos não nos aceitariam — murmurava George Ten. — Um dia, hão de nos aceitar.</p>
    <p>— Quando?</p>
    <p>— Dentro de alguns anos. Não importa exatamente em quanto tempo. O homem não existe sozinho, mas sim é parte de um padrão enormemente complexo de formas de vida. Quando uma parte suficiente do padrão estiver robotizada, então seremos aceitos.</p>
    <p>— E depois?</p>
    <p>Mesmo considerando que era uma prolongada conversa, como que de gagos, depois disso houve uma pausa anormalmente longa.</p>
    <p>Por fim, George Ten cochichou: — Deixe-me testar seu pensamento. Você está equipado para aprender a aplicar adequadamente a Segunda Lei. Você precisa decidir a qual ser humano obedecer e a qual não obedecer, quando houver conflito de ordens. Ou, mesmo, se é para obedecer a um ser humano. Basicamente, que é que você precisa para executar isso?</p>
    <p>— Preciso definir a expressão “ser humano” — cochichou George Nine.</p>
    <p>— Como? Pela aparência? Pela sua constituição? Pelo tamanho e forma?</p>
    <p>—Não. De dois seres humanos, iguais em todos os aspectos externos, um pode ser inteligente, outro estúpido; um pode ser culto, outro ignorante; um amadurecido, outro infantil; um responsável, outro mau caráter.</p>
    <p>— Então, como define um ser humano?</p>
    <p>Quando a Segunda Lei me obriga a obedecer a um ser humano, preciso considerar que devo obedecer a um ser humano que esteja preparado, por sua mente, seu caráter e conhecimento, para me dar aquela ordem. E, onde mais de um ser humano estiver em jogo, aquele dentre eles que estiver melhor preparado por sua mente, caráter e conhecimento, para dar aquela ordem.</p>
    <p>— Nesse caso, como obedecerá à Primeira Lei?</p>
    <p>— Não permitindo que nenhum ser humano sofra qualquer mal nem mesmo por inação. Mas, não obstante, se por cada uma de todas as ações possíveis alguns seres humanos vierem a sofrer, então, agir de maneira tal que garanta que aquele ser humano melhor dotado em mente, caráter e conhecimento venha a sofrer o menor dos males.</p>
    <p>— Seus pensamentos concordam com os meus — sussurrou George Ten. — Preciso agora fazer a pergunta pela qual requisitei sua companhia. É algo que não ouso julgar por mim mesmo. Preciso ter seu julgamento, o julgamento de alguém fora do círculo de meus próprios pensamentos... Dos seres racionais que conheceu, quem possui a mente, o caráter e o conhecimento que você julga superiores aos dos demais, sem levar em conta a configuração e a forma, visto que isso é irrelevante?</p>
    <p>— Você — murmurou George Nine.</p>
    <p>— Mas sou um robô. Há no seu cérebro trilhas de critério para distinguir entre um robô, de metal, e um ser humano, de carne. Como pode então você me classificar entre os seres humanos?</p>
    <p>— Porque há nas trilhas de meu cérebro uma urgente necessidade de não levar em consideração a configuaração e a forma, ao julgar seres humanos, e isto é superior à distinção entre metal e carne. Você é um ser humano, George Ten, e melhor preparado que os outros.</p>
    <p>Foi a vez de George Ten murmurar: — É o mesmo que penso a seu respeito. Pelos critérios de julgamento em nós ínsitos, então, nós próprios estamos descobrindo que, dentro do significado das Três Leis, somos seres humanos, e mais ainda: seres humanos aos quais se deve dar prioridade em relação aos outros seres humanos.</p>
    <p>George Nine cochichou: — Que se passará, então, quando formos aceitos por esses outros?</p>
    <p>Novo cochicho, desta feita de George Ten: — Quando nós e os outros, a serem planejados ainda mais avançados do que nós mesmos, formos aceitos, ordenaremos nossas sociedades de maneira tal que uma sociedade, eventualmente, será formada, na qual seres-humanos-como-nós-mesmos serão, basicamente, protegidos de qualquer-mal. Pelas Três Leis, os seres-humanos-como-os-outros contam menos e nem devem ser obedecidos, nem devem ser protegidos quando isto interferir com a necessidade de obediência àqueles como nós, e com a necessidade de proteção àqueles como nós. Foi com isto em mente que direcionei a robotização da ecologia do mundo.</p>
    <p>A conversa durou um mês e o bruxuleio das trilhas positrônicas não era muito intenso. Entre eles, não havia necessidade de se dizer mais nada, mas, ocasionalmente, um pensamento não expresso bruxuleava dentro deles enquanto esperavam, com intérmina paciência, que os anos necessários passassem.</p>

    <h4>8a.</h4>

    <p>George Ten e George Nine estavam sozinhos.</p>
    <p>Seus pensamentos eram singularmente parecidos e nem podiam mesmo ser distingüíveis.</p>
    <p>Pensavam: Os seres-humanos-como-os-outros pode ser que nunca tenham tido a intenção de tornar nebulosa a distinção entre eles mesmos e os seres-humanos-como-os-Georges. Não obstante, assim tinham feito, inadvertidamente.</p>
    <p>Pode ser que agora percebessem seu engano e tentassem corrigi-lo, mas não. Em todas as consultas, a orientação dos Georges tinha sido com aquilo em mente.</p>
    <p>Custasse o que custasse, os Georges e os que se lhes seguissem em forma e espécie precisariam dominar. Tanto foi pedido, e qualquer outra trajetória foi tornada completamente impossível, pelas Três Leis Humânicas.</p>

    <p class="dinkus">⚫︎</p>

    <p class="spacebefore">A antologia <i>Final Stage</i> teve alguns problemas, depois de publicada. Aparentemente, o responsável pelas edições, na editora (que <i>não era</i> a Doubleday) decidira fazer algumas pequenas modificações nas histórias. É o tipo de coisa que freqüentemente aborrece os autores e, particularmente, aborrece Harlan Ellison (talvez justificadamente, pois o considero um profissional muito cuidadoso, com um estilo muito característico).</p>
    <p>Por conseguinte, recebi uma cópia de uma comprida e furiosa carta que Harlan escrevera aos editores, incluindo longas listas de trechos tais como ele originalmente os escrevera e como tinham sido publicados, com as razões pelas quais as mudanças tinham sido para pior. Harlan urgiu-me a ler de cabo a rabo minha história e então me unir a ele e aos outros no sentido de pressionar a editora.</p>
    <p>Sempre leio minhas histórias, quando publicadas, mas nunca me ocorre comparar a história publicada com o original. Naturalmente que eu percebería inserções ou supressões de certo vulto, mas nunca me dou conta do tipo de modificações menores que os <i>editores</i> sempre estão introduzindo. Sempre admito que essas modificações apenas minimizam pequenos enganos em meus escritos e, desta maneira, os melhoram.</p>
    <p>Entretanto, depois de receber a carta, comparei a história publicada e o original; comparei-as diligentemente. Foi uma tarefa tediosa e humilhante, pois achei exatamente quatro modificações de pouca monta, cada qual corrigindo um erro devido à falta de cuidado de minha parte. A única conclusão a que cheguei foi que o <i>editor</i> não achou minha história importante a ponto de se ocupar dela.</p>
    <p>Tive de escrever uma acanhada carta a Harlan, dizendo que, por uma questão de princípio, eu o apoiaria, mas que eu não podería dar gritos, dando-me por pessoalmente ultrajado, visto que minha história não havia sido alterada. Felizmente, minha ajuda foi desnecessária. Parece que Harlan levou a melhor e edições posteriores apesentaram, creio eu, suas histórias restauradas em sua virginal inocência.</p>
    <p>Um ponto de menor relevo: muitos leitores me escreveram, alarmados, porque lhes pareceu que “Para Que Vos Ocupeis Dele” pusera um fim a minhas histórias de robôs positrônicos. Tinham medo de que eu nunca mais escrevesse uma. Ridículo! Naturalmente que não pretendo parar de escrever histórias sobre robôs. Na verdade, desde que aquela “última” história foi escrita, escrevi uma. Aparece mais adiante, neste livro.</p>

    <p class="dinkus">⚫︎</p>

    <p class="spacebefore">Tive um bocado de amolações com a história seguinte.</p>
    <p>Depois que Judy-Lynn foi trabalhar na Ballantine Books, começou a publicar coletâneas de histórias originais de ficção científica e queria uma de mim. Sempre é difícil dizer um não para ela, e como sempre me considerei culpado no caso de “Intuição Feminina”, concordei.</p>
    <p>Comecei a história em 21 de julho de 1973. Fui escrevendo bem devagarinho. Depois de um certo tempo, porém, percebi que me metera num complicado conjunto de <i>flashbacks</i>. Assim, quando entreguei os originais a Judy-Lynn e ela me perguntou — Que é que <i>você</i> pensa de sua história? — repliquei, cautelosamente: — É preferível que você mesmo decida.</p>
    <p>Parece que, freqüentemente, os editores me perguntam isso. Penso que têm a idéia de que me é difícil mentir, de forma que, se não exibo prontamente um festivo entusiasmo, é porque há algo de errado com a história.</p>
    <p>Foi o que Judy-Lynn certamente pensou. Devolveuvme o original com uns poucos parágrafos de cáusticos comentários concentrados no fato de que eu me metera num complicado conjunto de <i>flashbacks</i><a id="fn-006" href="#fn006" epub:type="noteref"><sup>6</sup></a>.</p>
    <p>Passei os originais a Ben Bova, responsável por <i>Analog Science Fiction</i>: rejeitou-os no mesmo dia. Me disse que lhe parecia que eu estava tentando embrulhar antecedentes demais numa história de dez mil palavras. Lá tinha eu material para uma novela — e ele queria que eu escrevesse essa novela.</p>
    <p>Isto me desanimou. Naquela ocasião, não havia nenhuma maneira de eu me interessar em escrever uma novela, de forma que me limitei a retirar a história.<a id="fn-007" href="#fn007" epub:type="noteref"><sup>7</sup></a></p>
    <p>Neste meio tempo, todavia, <i>Galaxy</i> passou a ter um novo responsável por publicações, um jovem muito agradável, chamado James Baen. Chamou-me e perguntou se poderia possivelmente ter uma história para ele. Disse-lhe que a única que tinha era uma novelazinha denominada “Estranho no Paraíso”. Contudo, disse-lhe eu, tinha sido rejeitada por Judy-Lynn e por Ben, de forma que eu hesitava em entregar-lha.</p>
    <p>Com muita personalidade, ele respondeu que cada editor tinha o direito de decidir por si mesmo. Destarte, enviei-lhe os originais e ele gostou deles. A novelazinha apareceu no número de Maio-Junho de 1974 de <i>If</i>, a revista-irmã de <i>Galaxy</i>. Lamentavelmente, <i>If</i>, desde aquela ocasião, cessou de ser publicada. (Se ocorrer a algum gentil leitor que isto é um exemplo de causa e efeito, não o é.)</p>

    <aside id="fn006" epub:type="footnote">
        <p class="spacebefore footnote"><a href="#fn-006"><sup>6</sup></a> Freqüentemente me perguntam se recebo recusas e invariavelmente a pessoa que pergunta fica embatucada quando digo — Lógico que sim. Aqui está um exemplo. Não só a história foi rejeitada uma vez, mas foi, como depois explico, rejeitada duas vezes.</p>
    </aside>

    <aside id="fn007" epub:type="footnote">
        <p class="spacebefore footnote"><a href="#fn-007"><sup>7</sup></a> Por falar nisso: algumas pessoas pensam que conhecer editores traz uma grande vantagem. Tanto Judy-Lynn como Ben estão entre meus amigos mais chegados, mas nenhum dos dois hesita um minuto quando é o caso de rejeitar minhas histórias, quando acham que não é o que queriam. Felizmente, tais rejeições não afetam a amizade.</p>
    </aside>
</body>

</html>